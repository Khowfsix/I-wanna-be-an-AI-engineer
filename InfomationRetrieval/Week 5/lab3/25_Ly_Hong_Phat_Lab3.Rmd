---
title: "Lab 3 - Query Processing"
date: "2023/02/28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Code mẫu

Để thực hiện bài lab này bạn sẽ sử dụng phần code mẫu trong file **lab3.zip** và viết thêm các hàm hoặc các lớp để thực hiện các công việc theo yêu cầu bên dưới. Bài lab này sẽ sử dụng lại và làm tiếp theo bài lab2.

## Cách nộp bài làm

Bạn sẽ nộp lại project đã làm (**chỉ bao gồm các file .java**, **không bao gồm các thư viện .jar** trong project). Ngoài ra, bạn cần nộp file báo cáo chứa java code và kết quả dùng file **Lab3.Rmd** được dung cấp sẵn. Đây là file **Rmarkdown**. **Markdown** là cú pháp đơn giản cho phép dễ dạng tạo các báo. **Rmarkdown** tích hợp code R với cú pháp **Markdown** để có thể tạo ra các báo cáo vừa có text, code và kết quả. Ở đây ta không dùng code R mà dùng java. Xem thêm cú pháp của Rmarkdown ở <https://github.com/rstudio/cheatsheets/raw/master/rmarkdown-2.0.pdf> để biết cách viết. Dùng **RStudio** để soạn thảo và viết báo cáo. Khi cần biên dịch ra file .html thì nhấp vào **Knit** và chọn **Knit to html**. Nếu cần tìm hiểu thêm về **Rmarkdown** thì có thể xem ở <https://bookdown.org/yihui/rmarkdown/>.

## Yêu cầu

### Lập chỉ mục bộ sưu tập tài liệu (document collection)

Đầu tiên, bạn cần thực thi file **LuceneBuildIndex.java** trong package **search** của project để lập chỉ mục bộ sưu tập tài liệu cho sẵn (file **example_corpus.gz** trong thư mục **docs** của project).

### Hiện thực các mô hình không gian vector (VSM) dùng chỉ mục đã tạo

Tiếp theo, bạn sẽ hiện thực một vài hàm xếp hạng dùng Lucene. Bạn sẽ phải duyệt qua posting list của từng từ (term) trong query từ index đã xây dựng được. Bạn cần hiện thực các hàm `taatTFIDF`, `daatTFIDF`, `taatVSMCosine`, và `daatVSMCosine` trong file **LuceneSearchIndex.java**.

1.  **Hiện thực mô hình không gian vector với hàm xếp hạng TF-IDF**

-   Hàm xếp hạng này được mô tả bởi công thức sau: $$f(d,q) = \sum_{w \in q} freq(w, d) \times log \frac{N + 1}{n_w + 1}$$ Trong đó:

    -   $f(d, q)$ là giá trị mô tả mức độ liên quan của tài liệu $d$ với truy vấn $q$,

    -   $freq(w, d)$ là tần số của từ $w$ trong tài liệu $d$,

    -   $n_w$ là số tài liệu chứa từ $w$ trong collection (còn gọi là *document frequency* của $w$ trong collection),

    -   $N$ là số tài liệu trong collection.

a.  **Dùng chiến lược term-at-a-time (TAAT)**

```{java}
/**
 * Hiện thực TFxIDF dùng chiến lược term-at-a-time (taat)
 *
 * @param index   Lucene index reader
 * @param field   index field để tìm query
 * @param queryTerms  Danh sách các query term
 *            
 * @return  Danh sách kết quả (sắp xếp theo độ liên quan)
 */
public static List<SearchResult> taatTFIDF(IndexReader index, String field, List<String> queryTerms)
		throws IOException {

	// Đây là hiện thực mẫu cho hàm TFxIDF dùng chiến lược term-at-a-time (taat)
	List<SearchResult> rs = null;

	if (!queryTerms.isEmpty()) {
		rs = new ArrayList<SearchResult>();
		HashMap<Integer, Double> hm = new HashMap<Integer, Double>();

		for (String term : queryTerms) {
			PostingsEnum posting = MultiTerms.getTermPostingsEnum(index, field, new BytesRef(term),
					PostingsEnum.POSITIONS);
			if (posting != null) { // nếu term không có trong document nào cả, posting sẽ là null
				int docid;
				int tf;
				int n; // document frequency của term trong "text" field
				int N; // tổng số document trong index
				double idf; // cộng 1 vào N và n để tránh trường hợp N = 0 và n = 0
				double tfidf;

				N = index.numDocs();
				n = index.docFreq(new Term(field, term));
				idf = Math.log((N + 1.0) / (n + 1.0));
				while ((docid = posting.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
					tf = posting.freq();
					tfidf = tf * idf;
					if (!hm.containsKey(docid))
						hm.put(docid, tfidf);
					else
						hm.put(docid, tfidf + hm.get(docid));
				}
			}
		}

		for (int docid : hm.keySet()) {
			String docno = LuceneUtils.getDocno(index, "docno", docid);
			rs.add(new SearchResult(docid, docno, hm.get(docid)));
		}
	}

	rs.sort(Comparator.comparing(SearchResult::getScore).reversed());
	return rs;
}
```

Kết quả sau khi chạy với input đã cho (top-10 kết quả đầu tiên, sắp xếp theo độ liên quan giảm dần) là:

    0  0 ACM-1148204  1   9.68601321        taatTFIDF
    0  0 ACM-564408   2   9.08984702        taatTFIDF
    0  0 ACM-2009998  3   8.24864674        taatTFIDF
    0  0 ACM-383972   4   8.24864674        taatTFIDF
    0  0 ACM-1277796  5   8.16696871        taatTFIDF
    0  0 ACM-1390416  6   8.08529068        taatTFIDF
    0  0 ACM-1835650  7   7.92193462        taatTFIDF
    0  0 ACM-860437   8   7.84025659        taatTFIDF
    0  0 ACM-2609503  9   7.16241237        taatTFIDF
    0  0 ACM-1009026  10  6.99905631        taatTFIDF

b.  **Dùng chiến lược document-at-a-time (DAAT)**

```{java}
/**
 * Hiện thực TFxIDF dùng chiến lược document-at-a-time (daat)
 *
 * @param index   Lucene index reader
 * @param field   index field để tìm query
 * @param queryTerms  Danh sách các query term
 *            
 * @return  Danh sách kết quả (sắp xếp theo độ liên quan)
 */
public static List<SearchResult> daatTFIDF(IndexReader index, String field, List<String> queryTerms)
		throws IOException {
	// Viết phần hiện thực của bạn ở đây
	// Bạn có thể viết thêm các hàm phụ trợ nếu cần thiết
	// Đây là hiện thực mẫu cho hàm TFxIDF dùng chiến lược document-at-a-time (daat)
	PriorityQueue<SearchResult> pq = new PriorityQueue<>((o1, o2) -> o1.getScore().compareTo(o2.getScore()));

	List<String> qterms_filtered = new ArrayList<>();
	for (String term : queryTerms) {
		if (index.docFreq(new Term(field, term)) > 0) {
			qterms_filtered.add(term);
		}
	}
	queryTerms = qterms_filtered;

	int k = 10; // priority queue size
	int[] cursors = new int[queryTerms.size()]; // cursors point to current docid for each posting
	double[] idfs = new double[queryTerms.size()]; // idfs for each query term
	PostingsEnum[] postings = new PostingsEnum[queryTerms.size()]; // postings for each query term

	for (int ix = 0; ix < queryTerms.size(); ix++) {
		postings[ix] = MultiTerms.getTermPostingsEnum(index, field, new BytesRef(queryTerms.get(ix)),
				PostingsEnum.FREQS);
		cursors[ix] = postings[ix].nextDoc();
		idfs[ix] = getIDF(index, field, queryTerms.get(ix));
	}

	String docno;
	while (true) {
		int docid_smallest = Integer.MAX_VALUE;
		for (int cursor : cursors) {
			if (cursor >= 0 && cursor < docid_smallest) {
				docid_smallest = cursor;
			}
		}
		if (docid_smallest == Integer.MAX_VALUE) {
			break;
		}
		double score = 0;
		for (int ix = 0; ix < cursors.length; ix++) {
			if (cursors[ix] == docid_smallest) {
				score += idfs[ix] * postings[ix].freq(); // cumulative sum of tf-idf for each doc
				cursors[ix] = postings[ix].nextDoc();
			}
		}

		docno = LuceneUtils.getDocno(index, "docno", docid_smallest);
		if (pq.size() < k) {
			pq.add(new SearchResult(docid_smallest, docno, score));
		} else {
			SearchResult result = pq.peek();
			if (score > result.getScore()) {
				pq.poll();
				pq.add(new SearchResult(docid_smallest, docno, score));
			}
		}
	}

	List<SearchResult> results = new ArrayList<>(pq.size());
	results.addAll(pq);
	Collections.sort(results, (o1, o2) -> o2.getScore().compareTo(o1.getScore()));

	return results;
}

public static double getIDF(IndexReader index, String field, String term) throws IOException {
	int N = index.numDocs();
	int n = index.docFreq(new Term(field, term));
	return (float) Math.log((N + 1.0) / (n + 1.0));
}
```

Kết quả sau khi chạy với input đã cho là (copy kết quả paste vào đây, giữa cặp dấu `...`):

    0  0 ACM-1148204  1   9.68601334        daatTFIDF
    0  0 ACM-564408   2   9.08984715        daatTFIDF
    0  0 ACM-2009998  3   8.24864686        daatTFIDF
    0  0 ACM-383972   4   8.24864686        daatTFIDF
    0  0 ACM-1277796  5   8.16696882        daatTFIDF
    0  0 ACM-1390416  6   8.08529079        daatTFIDF
    0  0 ACM-1835650  7   7.92193472        daatTFIDF
    0  0 ACM-860437   8   7.84025669        daatTFIDF
    0  0 ACM-2609503  9   7.16241246        daatTFIDF
    0  0 ACM-1009026  10  6.99905640        daatTFIDF

2.  **Hiện thực mô hình không gian vector với hàm xếp hạng cosine**

-   Hàm xếp hạng này được mô tả bởi công thức sau: $$f(d,q) = \frac{\sum_{w \in q} freq(w, q) \times freq(w, d)}{\sqrt{\sum_{w \in q} freq(w, q)^2} \times \sqrt{\sum_{w \in d} freq(w, d)^2}} $$ Trong đó:

    -   $f(d, q)$ là giá trị mô tả mức độ liên quan của tài liệu $d$ với truy vấn $q$,

    -   $freq(w, q)$, $freq(w, d)$ lần lượt là tần số của từ $w$ trong truy vấn $q$ và tài liệu $d$.

a.  **Dùng chiến lược term-at-a-time (TAAT)**

```{java}
// Đếm tần số xuất hiện của từ word trong query
public static int freqQ(String word, List<String> query) {
	int freqWq = 0;
	for (String t : query) {
		if (t.equals(word)) {
			freqWq = freqWq + 1;
		}
	}
	return freqWq;
}

//	Tính VSMCosine
public static double getVSMCosine(IndexReader index, String field, String term, List<String> queryTerms)
		throws IOException {
//		get sum Freq(w,q)^2
	List<Integer> QF_List = new ArrayList<Integer>();
	double SumFreqWq_2 = 0;
	for (int i = 0; i < queryTerms.size(); i++) {
		QF_List.add(freqQ(queryTerms.get(i), queryTerms));
		SumFreqWq_2 += QF_List.get(i) * QF_List.get(i);
	}

//		get sum Freq(w,d)^2
	double SumFreqDq_2 = 0;
	List<Integer> TF_List = new ArrayList<Integer>();
	for (int i = 0; i < queryTerms.size(); i++) {
		String termString = queryTerms.get(i);

//			Lấy postingList của term
		PostingsEnum posting = MultiTerms.getTermPostingsEnum(index, field, new BytesRef(termString),
				PostingsEnum.FREQS);

		if (posting != null) {
			TF_List.add(posting.freq());
			SumFreqDq_2 += TF_List.get(i) * TF_List.get(i);
		}
	}

	double score = (freqQ(term, queryTerms)) / Math.sqrt(SumFreqWq_2 * SumFreqDq_2);
	return score;
}

/**
 * Hiện thực VSM (cosine similarity) dùng chiến lược term-at-a-time (taat)
 *
 * @param index   Lucene index reader
 * @param field   index field để tìm query
 * @param queryTerms  Danh sách các query term
 *            
 * @return  Danh sách kết quả (sắp xếp theo độ liên quan)
 */
public static List<SearchResult> taatVSMCosine(IndexReader index, String field, List<String> queryTerms)
		throws IOException {
	// Viết phần hiện thực của bạn ở đây
	// Bạn có thể viết thêm các hàm phụ trợ nếu cần thiết

	List<SearchResult> searchVSMCosineList = new ArrayList<SearchResult>();

//		sumFreqWq bình phương: bình phương tổng tần số của từ w trong truy vấn q
	List<Integer> qfList = new ArrayList<Integer>();
	double SumFreqWq_2 = 0;
	for (int i = 0; i < queryTerms.size(); i++) {
		String term = queryTerms.get(i);
		qfList.add(freqQ(term, queryTerms));
		SumFreqWq_2 += qfList.get(i) * qfList.get(i);
	}
	List<Integer> tfList = new ArrayList<Integer>();

	for (int i = 0; i < queryTerms.size(); i++) {
		String termString = queryTerms.get(i);

//			Lấy postingList của term
		PostingsEnum posting = MultiTerms.getTermPostingsEnum(index, field, new BytesRef(termString),
				PostingsEnum.FREQS);

//			Term term = new Term(field, termString);
		if (posting != null) {
			int docid;

			while ((docid = posting.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
//					Lấy docno để lưu vào kết quả
				String docno = LuceneUtils.getDocno(index, "docno", docid);

//					Tính term frequency TF
				int freqWd = posting.freq();
				tfList.add(freqWd);

//					Tính tần số của từ w trong truy vấn q
				double fredWq = qfList.get(i);

//					Tính score của term này
				double score = (fredWq * freqWd);

				Boolean isExist = false;
				// Tìm trong kết quả xem đã tồn tại chưa
				for (SearchResult doc : searchVSMCosineList) {
					if (doc.docno.equals(docno)) {
						// Cộng dồn score nếu đã tồn tại trong kết quả
						doc.score += score;
						isExist = true;
						break;
					}
				}
				// Nếu chưa tồn tại thì thêm mới
				if (!isExist) {
					searchVSMCosineList.add(new SearchResult(docid, docno, score));
				}
			}
		}
	}

//		sumTF_2: tổng TF bình phương
	double sumTF_2 = 0;
	for (int tf : tfList) {
		sumTF_2 += tf * tf;
	}

	for (SearchResult score : searchVSMCosineList) {
		double newScore = score.getScore() / (Math.sqrt(SumFreqWq_2) * Math.sqrt(sumTF_2));
		score.setScore(newScore);
	}

//		sắp xếp theo score
	for (int i = 0; i < searchVSMCosineList.size() - 1; i++) {
		for (int j = i + 1; j < searchVSMCosineList.size(); j++) {
			SearchResult firstDoc = searchVSMCosineList.get(i);
			SearchResult secDoc = searchVSMCosineList.get(j);
			if (firstDoc.score < secDoc.score) {
				SearchResult temp = new SearchResult(searchVSMCosineList.get(i).docid,
						searchVSMCosineList.get(i).docno, searchVSMCosineList.get(i).score);
				searchVSMCosineList.get(i).docid = searchVSMCosineList.get(j).docid;
				searchVSMCosineList.get(i).docno = searchVSMCosineList.get(j).docno;
				searchVSMCosineList.get(i).score = searchVSMCosineList.get(j).score;
				searchVSMCosineList.get(j).docid = temp.docid;
				searchVSMCosineList.get(j).docno = temp.docno;
				searchVSMCosineList.get(j).score = temp.score;
			}
		}
	}

	return searchVSMCosineList;
}
```

Kết quả sau khi chạy với input đã cho là (copy kết quả paste vào đây, giữa cặp dấu `...`):

    0  0 ACM-1148204  1   0.25607376    taatVSMCosine
    0  0 ACM-564408   2   0.23473428    taatVSMCosine
    0  0 ACM-1390416  3   0.21339480    taatVSMCosine
    0  0 ACM-1277796  4   0.21339480    taatVSMCosine
    0  0 ACM-2009998  5   0.21339480    taatVSMCosine
    0  0 ACM-860437   6   0.21339480    taatVSMCosine
    0  0 ACM-1835650  7   0.21339480    taatVSMCosine
    0  0 ACM-383972   8   0.21339480    taatVSMCosine
    0  0 ACM-1009026  9   0.19205532    taatVSMCosine
    0  0 ACM-2609503  10  0.19205532    taatVSMCosine

b.  **Dùng chiến lược document-at-a-time (DAAT)**

```{java}
// Đếm tần số xuất hiện của từ word trong query
public static int freqQ(String word, List<String> query) {
	int freqWq = 0;
	for (String t : query) {
		if (t.equals(word)) {
			freqWq = freqWq + 1;
		}
	}
	return freqWq;
}

//	Tính VSMCosine
public static double getVSMCosine(IndexReader index, String field, String term, List<String> queryTerms)
		throws IOException {

//		get sum Freq(w,q)^2
	List<Integer> QF_List = new ArrayList<Integer>();
	double SumFreqWq_2 = 0;
	for (int i = 0; i < queryTerms.size(); i++) {
		QF_List.add(freqQ(queryTerms.get(i), queryTerms));
		SumFreqWq_2 += QF_List.get(i) * QF_List.get(i);
	}

//		get sum Freq(w,d)^2
	double SumFreqDq_2 = 0;
	List<Integer> TF_List = new ArrayList<Integer>();
	for (int i = 0; i < queryTerms.size(); i++) {
//			Lấy postingList của term
		PostingsEnum posting = MultiTerms.getTermPostingsEnum(index, field, new BytesRef(queryTerms.get(i)),
				PostingsEnum.FREQS);
		while ((posting.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {
			TF_List.add(posting.freq());
			SumFreqDq_2 += TF_List.get(i) * TF_List.get(i);
		}
	}
//		System.out.println("SumFreqDq_2: " + SumFreqDq_2);

	double score = (freqQ(term, queryTerms)) / Math.sqrt(SumFreqWq_2 * SumFreqDq_2);
	return score;
}

/**
 * Hiện thực VSM (cosine similarity) dùng chiến lược document-at-a-time (daat)
 *
 * @param index   Lucene index reader
 * @param field   index field để tìm query
 * @param queryTerms  Danh sách các query term
 *            
 * @return  Danh sách kết quả (sắp xếp theo độ liên quan)
 */
public static List<SearchResult> daatVSMCosine(IndexReader index, String field, List<String> queryTerms)
		throws IOException {
	// Viết phần hiện thực của bạn ở đây
	// Bạn có thể viết thêm các hàm phụ trợ nếu cần thiết

	// Đây là hiện thực mẫu cho hàm VSMCosine dùng chiến lược document-at-a-time
	// (daat)
	PriorityQueue<SearchResult> pq = new PriorityQueue<>((o1, o2) -> o1.getScore().compareTo(o2.getScore()));

	// Lọc các từ không có trong bất kỳ tài liệu nào
	List<String> qterms_filtered = new ArrayList<>();
	for (String term : queryTerms) {
		if (index.docFreq(new Term(field, term)) > 0) {
			qterms_filtered.add(term);
		}
	}
	queryTerms = qterms_filtered;

	int k = 10; // chiều dài queue
	int[] cursors = new int[queryTerms.size()]; // con trỏ trỏ docid hiện tại của mỗi posting list
	double[] vsmCosines = new double[queryTerms.size()]; // vsmCosine của mỗi query term
	PostingsEnum[] postings = new PostingsEnum[queryTerms.size()]; // postings của mỗi query term

	for (int ix = 0; ix < queryTerms.size(); ix++) {
		postings[ix] = MultiTerms.getTermPostingsEnum(index, field, new BytesRef(queryTerms.get(ix)),
				PostingsEnum.FREQS);
		cursors[ix] = postings[ix].nextDoc();
		vsmCosines[ix] = getVSMCosine(index, field, queryTerms.get(ix), queryTerms);
	}

	String docno;
	while (true) {
		int docid_smallest = Integer.MAX_VALUE;
		for (int cursor : cursors) {
			if (cursor >= 0 && cursor < docid_smallest) {
				docid_smallest = cursor;
			}
		}
		if (docid_smallest == Integer.MAX_VALUE) {
			break;
		}

		double score = 0;
		for (int ix = 0; ix < cursors.length; ix++) {
			if (cursors[ix] == docid_smallest) {
				score += vsmCosines[ix] * postings[ix].freq();
				cursors[ix] = postings[ix].nextDoc();
			}
		}

		docno = LuceneUtils.getDocno(index, "docno", docid_smallest);
		if (pq.size() < k) {
			pq.add(new SearchResult(docid_smallest, docno, score));
		} else {
			SearchResult result = pq.peek();
			if (score > result.getScore()) {
				pq.poll();
				pq.add(new SearchResult(docid_smallest, docno, score));
			}
		}
	}

	List<SearchResult> results = new ArrayList<>(pq.size());
	results.addAll(pq);
	Collections.sort(results, (o1, o2) -> o2.getScore().compareTo(o1.getScore()));

	return results;
}
```

Kết quả sau khi chạy với input đã cho là (copy kết quả paste vào đây, giữa cặp dấu `...`):

    0  0 ACM-1148204  1   0.54100178    daatVSMCosine
    0  0 ACM-564408   2   0.49591830    daatVSMCosine
    0  0 ACM-2009998  3   0.45083482    daatVSMCosine
    0  0 ACM-383972   4   0.45083482    daatVSMCosine
    0  0 ACM-1277796  5   0.45083482    daatVSMCosine
    0  0 ACM-860437   6   0.45083482    daatVSMCosine
    0  0 ACM-1390416  7   0.45083482    daatVSMCosine
    0  0 ACM-1835650  8   0.45083482    daatVSMCosine
    0  0 ACM-1009026  9   0.40575134    daatVSMCosine
    0  0 ACM-2609503  10  0.40575134    daatVSMCosine
